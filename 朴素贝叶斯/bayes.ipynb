{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.朴素贝叶斯种类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.GauusianNB  高斯分布（正态分布）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "import pandas as pd \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据集\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#且分数据集\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(iris.data, iris.target,random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建模\n",
    "clf = GaussianNB()\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 1, 0, 1,\n",
       "       2, 1, 0, 2, 2, 1, 0, 0, 0, 1, 2, 0, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在测试集上执行预测，proba到处的是每个样本属于某类的概率\n",
    "clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 2.32926069e-017, 1.81656357e-023],\n",
       "       [4.28952299e-154, 2.48576754e-002, 9.75142325e-001],\n",
       "       [1.00000000e+000, 7.45528845e-018, 3.79800436e-024],\n",
       "       [3.59748710e-076, 9.99751806e-001, 2.48194200e-004],\n",
       "       [2.20411871e-239, 4.45798016e-009, 9.99999996e-001],\n",
       "       [1.23795145e-173, 1.95814902e-003, 9.98041851e-001],\n",
       "       [2.45866589e-206, 2.34481513e-007, 9.99999766e-001],\n",
       "       [1.00000000e+000, 2.61810906e-017, 2.67446831e-023],\n",
       "       [3.07448595e-259, 9.07196639e-011, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.14549667e-010, 3.00314173e-017],\n",
       "       [1.64566141e-101, 9.87428016e-001, 1.25719837e-002],\n",
       "       [1.00000000e+000, 5.62770009e-016, 8.77233124e-022],\n",
       "       [1.00000000e+000, 9.78098062e-014, 4.81247272e-020],\n",
       "       [1.00000000e+000, 3.96616431e-015, 3.17162008e-021],\n",
       "       [2.58159395e-110, 7.85918892e-001, 2.14081108e-001],\n",
       "       [8.01004975e-208, 8.36611920e-006, 9.99991634e-001],\n",
       "       [2.27845999e-193, 5.52863568e-004, 9.99447136e-001],\n",
       "       [2.52133012e-090, 9.94597495e-001, 5.40250471e-003],\n",
       "       [1.00000000e+000, 4.06675976e-017, 2.53312064e-023],\n",
       "       [3.29537129e-123, 9.22312452e-001, 7.76875484e-002],\n",
       "       [1.00000000e+000, 4.66765440e-017, 1.99662820e-023],\n",
       "       [7.54708431e-074, 9.99690656e-001, 3.09343577e-004],\n",
       "       [6.27117035e-136, 1.83265786e-001, 8.16734214e-001],\n",
       "       [4.68960290e-103, 9.82756006e-001, 1.72439943e-002],\n",
       "       [1.00000000e+000, 2.15636250e-014, 2.25086772e-020],\n",
       "       [5.92924136e-199, 5.41122729e-007, 9.99999459e-001],\n",
       "       [4.07679795e-141, 7.38689632e-002, 9.26131037e-001],\n",
       "       [2.77929930e-083, 9.99806458e-001, 1.93541791e-004],\n",
       "       [1.00000000e+000, 4.48465501e-017, 4.36464333e-023],\n",
       "       [1.00000000e+000, 1.64440161e-014, 1.13341951e-021],\n",
       "       [1.00000000e+000, 8.68192867e-017, 6.71630735e-023],\n",
       "       [7.15007036e-050, 9.99997055e-001, 2.94492877e-006],\n",
       "       [1.73414331e-178, 2.06441448e-003, 9.97935586e-001],\n",
       "       [1.00000000e+000, 4.90168069e-019, 3.86471595e-024],\n",
       "       [1.35600871e-156, 2.28929843e-002, 9.77107016e-001],\n",
       "       [1.00000000e+000, 1.78544881e-015, 1.09390819e-020],\n",
       "       [1.86074590e-058, 9.99948860e-001, 5.11400371e-005],\n",
       "       [3.69548269e-057, 9.99992986e-001, 7.01435008e-006]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试准确率\n",
    "accuracy_score(ytest,clf.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.MultinomialNB(多项式朴素贝叶斯）  多元离散值常用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.BernonlliNB(伯努利朴素贝叶斯）  二元离散值或者很稀疏的多元离散值常用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.朴素贝叶斯之鸢尾花数据实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3       4\n",
       "0  5.1  3.5  1.4  0.2  setosa\n",
       "1  4.9  3.0  1.4  0.2  setosa\n",
       "2  4.7  3.2  1.3  0.2  setosa\n",
       "3  4.6  3.1  1.5  0.2  setosa\n",
       "4  5.0  3.6  1.4  0.2  setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = pd.read_csv('iris.csv', header = None)\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.切分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：随机切分训练集和测试集\n",
    "参数说明：\n",
    "        dataSet : 输入的数据集\n",
    "        rate : 训练集所占比例\n",
    "返回：切好的训练集和测试集\n",
    "\"\"\"\n",
    "def randSplit(dataSet, rate):\n",
    "    l = list(dataSet.index) #提取出索引\n",
    "    random.shuffle(l)  #随机打乱索引\n",
    "    dataSet.index = l #将打乱后的索引重新赋值给数据集\n",
    "    n = dataSet.shape[0] #总行数\n",
    "    m = int(n * rate) #训练集的数量\n",
    "    train = dataSet.loc[range(m),:] #提取前m个记录作为训练集\n",
    "    test  = dataSet.loc[range(m, n), :]\n",
    "    dataSet.index = range(dataSet.shape[0]) #更新原数据集的索引\n",
    "    test.index = range(test.shape[0])   #更新测试集索引\n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = randSplit(dataSet,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3           4\n",
       "0    6.8  3.2  5.9  2.3   virginica\n",
       "1    4.9  3.1  1.5  0.2      setosa\n",
       "2    5.6  3.0  4.1  1.3  versicolor\n",
       "3    6.0  2.2  5.0  1.5   virginica\n",
       "4    4.6  3.2  1.4  0.2      setosa\n",
       "5    4.4  3.0  1.3  0.2      setosa\n",
       "6    4.8  3.1  1.6  0.2      setosa\n",
       "7    6.1  2.9  4.7  1.4  versicolor\n",
       "8    5.0  3.2  1.2  0.2      setosa\n",
       "9    5.7  4.4  1.5  0.4      setosa\n",
       "10   6.1  2.8  4.7  1.2  versicolor\n",
       "11   6.5  3.0  5.5  1.8   virginica\n",
       "12   5.0  3.4  1.5  0.2      setosa\n",
       "13   6.4  3.2  5.3  2.3   virginica\n",
       "14   6.7  3.0  5.0  1.7  versicolor\n",
       "15   5.1  3.5  1.4  0.2      setosa\n",
       "16   5.8  2.7  4.1  1.0  versicolor\n",
       "17   5.8  2.7  5.1  1.9   virginica\n",
       "18   5.4  3.4  1.7  0.2      setosa\n",
       "19   6.4  2.8  5.6  2.2   virginica\n",
       "20   6.3  2.5  4.9  1.5  versicolor\n",
       "21   6.9  3.2  5.7  2.3   virginica\n",
       "22   6.6  2.9  4.6  1.3  versicolor\n",
       "23   5.8  2.8  5.1  2.4   virginica\n",
       "24   5.8  2.6  4.0  1.2  versicolor\n",
       "25   6.5  3.2  5.1  2.0   virginica\n",
       "26   4.8  3.0  1.4  0.1      setosa\n",
       "27   7.7  2.6  6.9  2.3   virginica\n",
       "28   6.5  3.0  5.2  2.0   virginica\n",
       "29   6.5  3.0  5.8  2.2   virginica\n",
       "..   ...  ...  ...  ...         ...\n",
       "90   6.3  3.3  6.0  2.5   virginica\n",
       "91   6.4  3.2  4.5  1.5  versicolor\n",
       "92   5.7  2.9  4.2  1.3  versicolor\n",
       "93   5.1  3.8  1.9  0.4      setosa\n",
       "94   5.1  3.3  1.7  0.5      setosa\n",
       "95   6.2  2.2  4.5  1.5  versicolor\n",
       "96   5.9  3.0  4.2  1.5  versicolor\n",
       "97   7.7  2.8  6.7  2.0   virginica\n",
       "98   6.9  3.1  5.4  2.1   virginica\n",
       "99   5.6  2.7  4.2  1.3  versicolor\n",
       "100  5.7  2.6  3.5  1.0  versicolor\n",
       "101  5.6  2.8  4.9  2.0   virginica\n",
       "102  6.3  2.9  5.6  1.8   virginica\n",
       "103  5.4  3.0  4.5  1.5  versicolor\n",
       "104  5.1  3.8  1.6  0.2      setosa\n",
       "105  6.0  3.0  4.8  1.8   virginica\n",
       "106  5.0  3.0  1.6  0.2      setosa\n",
       "107  5.7  2.8  4.5  1.3  versicolor\n",
       "108  4.9  3.6  1.4  0.1      setosa\n",
       "109  6.2  3.4  5.4  2.3   virginica\n",
       "110  6.0  2.2  4.0  1.0  versicolor\n",
       "111  7.3  2.9  6.3  1.8   virginica\n",
       "112  6.7  3.1  4.4  1.4  versicolor\n",
       "113  7.9  3.8  6.4  2.0   virginica\n",
       "114  4.9  2.4  3.3  1.0  versicolor\n",
       "115  5.0  2.0  3.5  1.0  versicolor\n",
       "116  6.4  2.7  5.3  1.9   virginica\n",
       "117  6.8  3.0  5.5  2.1   virginica\n",
       "118  6.7  3.3  5.7  2.5   virginica\n",
       "119  5.9  3.2  4.8  1.8  versicolor\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3           4\n",
       "0   4.7  3.2  1.3  0.2      setosa\n",
       "1   5.8  2.7  5.1  1.9   virginica\n",
       "2   6.7  2.5  5.8  1.8   virginica\n",
       "3   5.1  3.8  1.5  0.3      setosa\n",
       "4   7.2  3.2  6.0  1.8   virginica\n",
       "5   6.8  2.8  4.8  1.4  versicolor\n",
       "6   5.0  2.3  3.3  1.0  versicolor\n",
       "7   5.0  3.5  1.6  0.6      setosa\n",
       "8   6.7  3.3  5.7  2.1   virginica\n",
       "9   5.7  2.5  5.0  2.0   virginica\n",
       "10  4.6  3.4  1.4  0.3      setosa\n",
       "11  5.4  3.7  1.5  0.2      setosa\n",
       "12  6.1  2.8  4.0  1.3  versicolor\n",
       "13  6.9  3.1  4.9  1.5  versicolor\n",
       "14  6.5  2.8  4.6  1.5  versicolor\n",
       "15  5.1  3.7  1.5  0.4      setosa\n",
       "16  4.7  3.2  1.6  0.2      setosa\n",
       "17  4.4  3.2  1.3  0.2      setosa\n",
       "18  5.0  3.4  1.6  0.4      setosa\n",
       "19  5.4  3.9  1.3  0.4      setosa\n",
       "20  4.3  3.0  1.1  0.1      setosa\n",
       "21  5.2  4.1  1.5  0.1      setosa\n",
       "22  4.8  3.4  1.6  0.2      setosa\n",
       "23  5.5  2.4  3.7  1.0  versicolor\n",
       "24  5.1  3.5  1.4  0.3      setosa\n",
       "25  7.4  2.8  6.1  1.9   virginica\n",
       "26  5.9  3.0  5.1  1.8   virginica\n",
       "27  4.9  3.0  1.4  0.2      setosa\n",
       "28  5.7  2.8  4.1  1.3  versicolor\n",
       "29  5.6  2.5  3.9  1.1  versicolor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 构建高斯朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb_classify(train,test):\n",
    "    labels = train.iloc[:,-1].value_counts().index  #提取训练集的标签种类\n",
    "    mean = []  #存放每个类别的均值\n",
    "    std = []  #存放每个类别的方差\n",
    "    result = []  #存放测试集的预测结果\n",
    "    for i in labels:\n",
    "        item = train.loc[train.iloc[:,-1] == i, :]  #分别提取出每一种类别\n",
    "        m = item.iloc[:, : -1].mean()  #当前类别的平均值\n",
    "        s = np.sum((item.iloc[:,: -1] - m)**2)/(item.shape[0])  #当前类别的方差\n",
    "        mean.append(m) #将当前类别的平均值追加至列表\n",
    "        std.append(s) #将当前类别的方差追加至列表\n",
    "    means = pd.DataFrame(mean, index = labels)  #变成DF格式，索引为类标签\n",
    "    stds = pd.DataFrame(std, index = labels)  #变成DF格式，索引为类标签\n",
    "    for j in range(test.shape[0]):\n",
    "        iset = test.iloc[j,:-1].tolist() #当前测试实例\n",
    "        iprob = np.exp(-1*(iset - means)**2/(stds*2))/(np.sqrt(2*np.pi*stds))  #正态分布公式\n",
    "        prob = 1 #初始化当前实例总概率\n",
    "        for k in range(test.shape[1] - 1): #便利每个特征\n",
    "            prob *= iprob[k]  #特征概率之积即为当前实例概率\n",
    "            cla = prob.index[np.argmax(prob.values)] #返回最大概率的类别\n",
    "        result.append(cla)\n",
    "    test['predict'] = result\n",
    "    acc = (test.iloc[: ,-1] == test.iloc[:,-2]).mean()  #计算预测准确率\n",
    "    print(f'模型预测准确率为{acc}')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率为0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3           4     predict\n",
       "0   4.7  3.2  1.3  0.2      setosa      setosa\n",
       "1   5.8  2.7  5.1  1.9   virginica   virginica\n",
       "2   6.7  2.5  5.8  1.8   virginica   virginica\n",
       "3   5.1  3.8  1.5  0.3      setosa      setosa\n",
       "4   7.2  3.2  6.0  1.8   virginica   virginica\n",
       "5   6.8  2.8  4.8  1.4  versicolor  versicolor\n",
       "6   5.0  2.3  3.3  1.0  versicolor  versicolor\n",
       "7   5.0  3.5  1.6  0.6      setosa      setosa\n",
       "8   6.7  3.3  5.7  2.1   virginica   virginica\n",
       "9   5.7  2.5  5.0  2.0   virginica   virginica\n",
       "10  4.6  3.4  1.4  0.3      setosa      setosa\n",
       "11  5.4  3.7  1.5  0.2      setosa      setosa\n",
       "12  6.1  2.8  4.0  1.3  versicolor  versicolor\n",
       "13  6.9  3.1  4.9  1.5  versicolor   virginica\n",
       "14  6.5  2.8  4.6  1.5  versicolor  versicolor\n",
       "15  5.1  3.7  1.5  0.4      setosa      setosa\n",
       "16  4.7  3.2  1.6  0.2      setosa      setosa\n",
       "17  4.4  3.2  1.3  0.2      setosa      setosa\n",
       "18  5.0  3.4  1.6  0.4      setosa      setosa\n",
       "19  5.4  3.9  1.3  0.4      setosa      setosa\n",
       "20  4.3  3.0  1.1  0.1      setosa      setosa\n",
       "21  5.2  4.1  1.5  0.1      setosa      setosa\n",
       "22  4.8  3.4  1.6  0.2      setosa      setosa\n",
       "23  5.5  2.4  3.7  1.0  versicolor  versicolor\n",
       "24  5.1  3.5  1.4  0.3      setosa      setosa\n",
       "25  7.4  2.8  6.1  1.9   virginica   virginica\n",
       "26  5.9  3.0  5.1  1.8   virginica   virginica\n",
       "27  4.9  3.0  1.4  0.2      setosa      setosa\n",
       "28  5.7  2.8  4.1  1.3  versicolor  versicolor\n",
       "29  5.6  2.5  3.9  1.1  versicolor  versicolor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_classify(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.使用朴素贝叶斯进行文档分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数功能：创建实验数据集\n",
    "参数说明：无参数\n",
    "返回：\n",
    "    dataSet: 划分好的样本词条\n",
    "    classVec:类标签向量\n",
    "'''\n",
    "def loadDataSet():\n",
    "    dataSet = [['my', 'dog','flea','problems','help','please'],\n",
    "              ['maybe','not','take','him','to','dog','park','stupid'],\n",
    "              ['my','dalmation','is','so','cute','I','love','him'],\n",
    "              ['stop','posting','stupid','worthless','garbage'],\n",
    "              ['mr','licks','ate','my','steak','how','to','stop','him'],\n",
    "              ['quit','buying','worthless','dog','food','stupid']]   #切分好的七条\n",
    "    classVec = [0,1,0,1,0,1]   #类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇\n",
    "    return dataSet, classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet, classVec = loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['my', 'dog', 'flea', 'problems', 'help', 'please'],\n",
       " ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
       " ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
       " ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
       " ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
       " ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.构建词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：将划分的样本词条整理成词汇表（不重复）\n",
    "参数说明：\n",
    "        dataSet: 划分好的样本词条\n",
    "返回：\n",
    "    vocabList: 不重复的词汇表\n",
    "\"\"\"\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set()     #创建一个空的集合\n",
    "    for doc in dataSet:   #遍历dataSet种的每一条言论\n",
    "        vocabSet = vocabSet | set(doc)   #取并集\n",
    "        vocabList = list(vocabSet)\n",
    "    return vocabList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stupid', 'is', 'help', 'problems', 'cute', 'food', 'not', 'him', 'worthless', 'buying', 'love', 'dalmation', 'stop', 'mr', 'steak', 'take', 'dog', 'licks', 'ate', 'to', 'I', 'so', 'garbage', 'how', 'please', 'quit', 'my', 'flea', 'park', 'posting', 'maybe']\n"
     ]
    }
   ],
   "source": [
    "vocabList = createVocabList(dataSet)\n",
    "print(vocabList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.获得训练集向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：根据vocabList词汇表，将inputSet向量化，向量的每个元素为1或0\n",
    "参数说明：\n",
    "        vocabList:词汇表\n",
    "        inputSet : 切分好的词条列表中的一条\n",
    "返回：\n",
    "    returnVec :文档向量，词集模型\n",
    "\"\"\"\n",
    "def setOfwords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)         #创建一个其中所含元素都为0的向量\n",
    "    for word in inputSet:                    #遍历每个词条\n",
    "        if word in vocabList:                #如果词条存在于词汇表中，则变为1\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(f\"{word} is not in my Vocabulary!\")\n",
    "    return returnVec                        #返回文档向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有词条向量列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：生成训练集向量列表\n",
    "参数说明：\n",
    "        dataSet:划分好的样本词条\n",
    "返回：\n",
    "        trainMat:所有的词条向量组成的列表\n",
    "\"\"\"\n",
    "def get_trainMat(dataSet):\n",
    "    trainMat = []        #初始化向量列表\n",
    "    vocabList = createVocabList(dataSet)   #生成词汇表\n",
    "    for inputSet in dataSet:      #遍历样本词条中的每一条样本\n",
    "        returnVec = setOfwords2Vec(vocabList, inputSet)  #将当前词条向量化\n",
    "        trainMat.append(returnVec)      #追加到向量列表中\n",
    "    return trainMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMat = get_trainMat(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 朴素贝叶斯分类器训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：朴素贝叶斯分类器训练函数\n",
    "参数说明：\n",
    "        trainMat: 训练文档矩阵\n",
    "        classVec: 训练类别标签向量\n",
    "返回： \n",
    "        pOV：非侮辱类的条件概率数组\n",
    "        plV:侮辱类的条件概率数组\n",
    "        pAb:文档属于侮辱类的概率\n",
    "\"\"\"\n",
    "def trainNB(trainMat, classVec):\n",
    "    n = len(trainMat)       #计算训练的文档数目\n",
    "    m = len(trainMat[0])     #计算每篇文档的词条数\n",
    "    pAb = sum(classVec)/n    #文档属于侮辱类的概率\n",
    "    p0Num = np.zeros(m)      #词条出现初始化为0\n",
    "    p1Num = np.zeros(m)      #词条出现初始化为0\n",
    "    p0Denom = 0              #分母初始化为0\n",
    "    p1Denom = 0               #分母初始化为0\n",
    "    for i in range(n):       #遍历每一个文档\n",
    "        if classVec[i] == 1:   #统计属于侮辱类的条件概率所需的数据\n",
    "            p1Num += trainMat[i]\n",
    "            p1Denom += sum(trainMat[i])\n",
    "        else:                  #统级属于非侮辱类条件概率所需的数据\n",
    "            p0Num += trainMat[i]\n",
    "            p0Denom += sum(trainMat[i])\n",
    "    p1V = p1Num/p1Denom\n",
    "    p0V = p0Num/p0Denom\n",
    "    return p0V,p1V, pAb     #返回属于非侮辱类，侮辱类和文档属于侮辱类的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0V, p1V,pAb = trainNB(trainMat,classVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.04347826, 0.04347826, 0.04347826, 0.04347826,\n",
       "       0.        , 0.        , 0.08695652, 0.        , 0.        ,\n",
       "       0.04347826, 0.04347826, 0.04347826, 0.04347826, 0.04347826,\n",
       "       0.        , 0.04347826, 0.04347826, 0.04347826, 0.04347826,\n",
       "       0.04347826, 0.04347826, 0.        , 0.04347826, 0.04347826,\n",
       "       0.        , 0.13043478, 0.04347826, 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15789474, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05263158, 0.05263158, 0.05263158, 0.10526316, 0.05263158,\n",
       "       0.        , 0.        , 0.05263158, 0.        , 0.        ,\n",
       "       0.05263158, 0.10526316, 0.        , 0.        , 0.05263158,\n",
       "       0.        , 0.        , 0.05263158, 0.        , 0.        ,\n",
       "       0.05263158, 0.        , 0.        , 0.05263158, 0.05263158,\n",
       "       0.05263158])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pAb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 测试朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：朴素贝叶斯分类器分类函数\n",
    "参数说明：\n",
    "        vec2Classify:待分类的词条数组\n",
    "        pOV：非侮辱类的条件概率数组\n",
    "        plV:侮辱类的条件概率数组\n",
    "        pAb:文档属于侮辱类的概率\n",
    "返回：\n",
    "        0：属于非侮辱类\n",
    "        1：属于侮辱类\n",
    "\"\"\"\n",
    "def classifyNB(vec2Classify, p0V,p1V,pAb):\n",
    "    p1 = reduce(lambda x,y:x*y, vec2Classify * p1V) *pAb  #对应元素享程\n",
    "    p0 = reduce(lambda x,y:x*y, vec2Classify * p0V) *(1 - pAb)\n",
    "    print('p0:',p0)\n",
    "    print('p1:',p1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：朴素贝叶斯测试函数\n",
    "参数说明：\n",
    "        testVec :测试样本\n",
    "返回：测试样本的类别\n",
    "\"\"\"\n",
    "def testingNB(testVec):\n",
    "    dataSet, classVec = loadDataSet()    #创建实验样本\n",
    "    vocabList = createVocabList(dataSet)   #创建词汇表\n",
    "    trainMat = get_trainMat(dataSet)      #将实验样本向量化\n",
    "    p0V,p1V,pAb = trainNB (trianMat,classVec)  #训练朴素贝叶斯分类器\n",
    "    thisone = setOfwords2Vec(vocabList, testVec)    #测试样本向量化\n",
    "    if classifyNB(thisone, p0V,p1V,pAb) == 1:\n",
    "        print(testVec,'属于侮辱类')        #执行分类并打印分类结果\n",
    "    else:\n",
    "        print(testVec,'属于非侮辱类')      #执行分类并打印分类结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.朴素贝叶斯改进之拉普拉斯平滑\n",
    "(1)当某一类的概率为零时，连续相乘为零  ：增加一个小项\n",
    "(2)当概率都过小时，连续相乘，导致概率过小  ：取对数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB(trainMat, classVec):\n",
    "    n = len(trainMat)       #计算训练的文档数目\n",
    "    m = len(trainMat[0])     #计算每篇文档的词条数\n",
    "    pAb = sum(classVec)/n    #文档属于侮辱类的概率\n",
    "    p0Num = np.ones(m)      #词条出现初始化为1\n",
    "    p1Num = np.ones(m)      #词条出现初始化为1\n",
    "    p0Denom = 2              #分母初始化为2\n",
    "    p1Denom = 2               #分母初始化为2\n",
    "    for i in range(n):       #遍历每一个文档\n",
    "        if classVec[i] == 1:   #统计属于侮辱类的条件概率所需的数据\n",
    "            p1Num += trainMat[i]\n",
    "            p1Denom += sum(trainMat[i])\n",
    "        else:                  #统计属于非侮辱类条件概率所需的数据\n",
    "            p0Num += trainMat[i]\n",
    "            p0Denom += sum(trainMat[i])\n",
    "    p1V =np.log(p1Num/p1Denom)\n",
    "    p0V =np.log(p0Num/p0Denom)\n",
    "    return p0V,p1V, pAb     #返回属于非侮辱类，侮辱类和文档属于侮辱类的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0V, p1V,pAb = trainNB(trainMat,classVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.21887582, -2.52572864, -2.52572864, -2.52572864, -2.52572864,\n",
       "       -3.21887582, -3.21887582, -2.12026354, -3.21887582, -3.21887582,\n",
       "       -2.52572864, -2.52572864, -2.52572864, -2.52572864, -2.52572864,\n",
       "       -3.21887582, -2.52572864, -2.52572864, -2.52572864, -2.52572864,\n",
       "       -2.52572864, -2.52572864, -3.21887582, -2.52572864, -2.52572864,\n",
       "       -3.21887582, -1.83258146, -2.52572864, -3.21887582, -3.21887582,\n",
       "       -3.21887582])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.65822808, -3.04452244, -3.04452244, -3.04452244, -3.04452244,\n",
       "       -2.35137526, -2.35137526, -2.35137526, -1.94591015, -2.35137526,\n",
       "       -3.04452244, -3.04452244, -2.35137526, -3.04452244, -3.04452244,\n",
       "       -2.35137526, -1.94591015, -3.04452244, -3.04452244, -2.35137526,\n",
       "       -3.04452244, -3.04452244, -2.35137526, -3.04452244, -3.04452244,\n",
       "       -2.35137526, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "       -2.35137526])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pAb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(vec2Classify, p0V,p1V,pAb):\n",
    "    p1 = sum(vec2Classify * p1V) + np.log(pAb)  #对应元素相乘\n",
    "    p0 = sum(vec2Classify * p0V) + np.log(1 - pAb)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.朴素贝叶斯之垃圾邮件过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\"\"\"\n",
    "函数功能：创建实验数据集\n",
    "参数说明：\n",
    "        无参数\n",
    "返回：\n",
    "        dataSet:带标签的实验数据集（DF格式）\n",
    "\"\"\"\n",
    "def get_dataSet():\n",
    "    ham = []\n",
    "    #ham目录下的25个都读取\n",
    "    for i in range(1,26):\n",
    "        file_path = \"email/ham/%d.txt\"%(i)\n",
    "        data = open(file_path,encoding = 'gbk', errors ='ignore').read()\n",
    "        ham.append([data, 'ham'])\n",
    "    df1 = pd.DataFrame(ham)\n",
    "    spam = []\n",
    "    #spam目录下的25个都读取\n",
    "    for i in range(1,26):\n",
    "        file_path = \"email/spam/%d.txt\"%(i)\n",
    "        data = open(file_path,encoding = 'gbk', errors = 'ignore').read()\n",
    "        spam.append([data,'spam'])\n",
    "    df2 = pd.DataFrame(spam)\n",
    "    dataSet = pd.concat([df1,df2],ignore_index = True)\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi Peter,\\n\\nWith Jose out of town, do you wan...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yay to you both doing fine!\\n\\nI'm working on ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHat is going on there?\\nI talked to John on e...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yo.  I've been working on my running website. ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There was a guy at the gas station who told me...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello,\\n\\nSince you are an owner of at least o...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zach Hamm commented on your status.\\n\\nZach wr...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This e-mail was sent from a notification-only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hi Peter,\\n\\nThese are the only good scenic on...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ryan Whybrew commented on your status.\\n\\nRyan...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arvind Thirumalai commented on your status.\\n\\...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thanks Peter.\\n\\nI'll definitely check in on t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jay Stepp commented on your status.\\n\\nJay wro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinkedIn\\n\\nKerry Haloney requested to add you...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hi Peter,\\n \\nThe hotels are the ones that ren...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yeah I am ready.  I may not be here because Ja...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Benoit Mandelbrot 1924-2010\\n\\nBenoit Mandelbr...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hi Peter,\\n\\n    Sure thing.  Sounds good.  Le...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinkedIn\\n\\nJulius O requested to add you as a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I've thought about this and think it's possibl...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>we saw this on the way to the coast...thought ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hi Hommies,\\n\\nJust got a phone call from the ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\nSciFinance now automatically generates GPU-e...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ok I will be there by 10:00 at the latest.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>That is cold.  Is there going to be a retireme...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>--- Codeine 15mg -- 30 for $203.70 -- VISA Onl...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hydrocodone/Vicodin ES/Brand Watson\\n\\nVicodin...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Percocet 10/625 mg withoutPrescription 30 tabs...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>--- Codeine 15mg -- 30 for $203.70 -- VISA Onl...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OEM Adobe &amp; Microsoft softwares\\nFast order an...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bargains Here! Buy Phentermin 37.5 mg (K-25)\\n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bargains Here! Buy Phentermin 37.5 mg (K-25)\\n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OrderCializViagra Online &amp; Save 75-90%\\n\\n0nli...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Buy Ambiem (Zolpidem) 5mg/10mg @ $2.39/- pill\\...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>OrderCializViagra Online &amp; Save 75-90%\\n\\n0nli...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BuyVIAGRA 25mg, 50mg, 100mg,\\nBrandViagra, Fem...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A home based business opportunity is knocking ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Codeine (the most competitive price on NET!)\\n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Get Up to 75% OFF at Online WatchesStore\\n\\nDi...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Get Up to 75% OFF at Online WatchesStore\\n\\nDi...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Percocet 10/625 mg withoutPrescription 30 tabs...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Get Up to 75% OFF at Online WatchesStore\\n\\nDi...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>You Have Everything To Gain!\\n\\nIncredib1e gai...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Experience with BiggerPenis Today! Grow 3-inch...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0     1\n",
       "0   Hi Peter,\\n\\nWith Jose out of town, do you wan...   ham\n",
       "1   Yay to you both doing fine!\\n\\nI'm working on ...   ham\n",
       "2   WHat is going on there?\\nI talked to John on e...   ham\n",
       "3   Yo.  I've been working on my running website. ...   ham\n",
       "4   There was a guy at the gas station who told me...   ham\n",
       "5   Hello,\\n\\nSince you are an owner of at least o...   ham\n",
       "6   Zach Hamm commented on your status.\\n\\nZach wr...   ham\n",
       "7   This e-mail was sent from a notification-only ...   ham\n",
       "8   Hi Peter,\\n\\nThese are the only good scenic on...   ham\n",
       "9   Ryan Whybrew commented on your status.\\n\\nRyan...   ham\n",
       "10  Arvind Thirumalai commented on your status.\\n\\...   ham\n",
       "11  Thanks Peter.\\n\\nI'll definitely check in on t...   ham\n",
       "12  Jay Stepp commented on your status.\\n\\nJay wro...   ham\n",
       "13  LinkedIn\\n\\nKerry Haloney requested to add you...   ham\n",
       "14  Hi Peter,\\n \\nThe hotels are the ones that ren...   ham\n",
       "15  yeah I am ready.  I may not be here because Ja...   ham\n",
       "16  Benoit Mandelbrot 1924-2010\\n\\nBenoit Mandelbr...   ham\n",
       "17  Hi Peter,\\n\\n    Sure thing.  Sounds good.  Le...   ham\n",
       "18  LinkedIn\\n\\nJulius O requested to add you as a...   ham\n",
       "19  I've thought about this and think it's possibl...   ham\n",
       "20  we saw this on the way to the coast...thought ...   ham\n",
       "21  Hi Hommies,\\n\\nJust got a phone call from the ...   ham\n",
       "22  \\nSciFinance now automatically generates GPU-e...   ham\n",
       "23         Ok I will be there by 10:00 at the latest.   ham\n",
       "24  That is cold.  Is there going to be a retireme...   ham\n",
       "25  --- Codeine 15mg -- 30 for $203.70 -- VISA Onl...  spam\n",
       "26  Hydrocodone/Vicodin ES/Brand Watson\\n\\nVicodin...  spam\n",
       "27  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "28  Percocet 10/625 mg withoutPrescription 30 tabs...  spam\n",
       "29  --- Codeine 15mg -- 30 for $203.70 -- VISA Onl...  spam\n",
       "30  OEM Adobe & Microsoft softwares\\nFast order an...  spam\n",
       "31  Bargains Here! Buy Phentermin 37.5 mg (K-25)\\n...  spam\n",
       "32  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "33  Bargains Here! Buy Phentermin 37.5 mg (K-25)\\n...  spam\n",
       "34  OrderCializViagra Online & Save 75-90%\\n\\n0nli...  spam\n",
       "35  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "36  Buy Ambiem (Zolpidem) 5mg/10mg @ $2.39/- pill\\...  spam\n",
       "37  OrderCializViagra Online & Save 75-90%\\n\\n0nli...  spam\n",
       "38  BuyVIAGRA 25mg, 50mg, 100mg,\\nBrandViagra, Fem...  spam\n",
       "39  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "40  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "41  A home based business opportunity is knocking ...  spam\n",
       "42  Codeine (the most competitive price on NET!)\\n...  spam\n",
       "43  Get Up to 75% OFF at Online WatchesStore\\n\\nDi...  spam\n",
       "44  Get Up to 75% OFF at Online WatchesStore\\n\\nDi...  spam\n",
       "45  Percocet 10/625 mg withoutPrescription 30 tabs...  spam\n",
       "46  Get Up to 75% OFF at Online WatchesStore\\n\\nDi...  spam\n",
       "47  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "48  You Have Everything To Gain!\\n\\nIncredib1e gai...  spam\n",
       "49  Experience with BiggerPenis Today! Grow 3-inch...  spam"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = get_dataSet()\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用sklearn对训练集进行特征值抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()     #用来抽取文章特征\n",
    "tf.fit(dataSet[0])         #对所有内容进行训练\n",
    "data_tf = tf.transform(dataSet[0])   #对训练的内容进行特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12     ham\n",
       "40    spam\n",
       "34    spam\n",
       "46    spam\n",
       "23     ham\n",
       "20     ham\n",
       "37    spam\n",
       "35    spam\n",
       "47    spam\n",
       "16     ham\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data_tf,dataSet[1],test_size = 0.2)\n",
    "Xtest.shape[0]\n",
    "Ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#多项式朴素贝叶斯\n",
    "mnb = MultinomialNB ()   #获取模型\n",
    "mnb.fit(Xtrain, Ytrain)  #训练模型\n",
    "mnb.score(Xtest, Ytest)   #查看准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#伯努利分布朴素贝叶斯\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(Xtrain, Ytrain)\n",
    "bnb.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['Simhei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnbs = []\n",
    "bnbs = []\n",
    "for i in range(10):\n",
    "    mnb = MultinomialNB()\n",
    "    mnb_s = cross_val_score(mnb,data_tf,dataSet[1],cv = 10).mean()\n",
    "    mnbs.append(mnb_s)\n",
    "    bnb = BernoulliNB()\n",
    "    bnb_s =cross_val_score(bnb,data_tf,dataSet[1],cv = 10).mean()\n",
    "    bnbs.append(bnb_s)\n",
    "plt.plot(range(1,11),mnbs,label = '多项式朴素贝叶斯')\n",
    "plt.plot(range(1,11),bnbs,label = '伯努利朴素贝叶斯')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
